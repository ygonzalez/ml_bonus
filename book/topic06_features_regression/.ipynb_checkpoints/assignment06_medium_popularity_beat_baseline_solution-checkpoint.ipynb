{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://habrastorage.org/webt/ia/m9/zk/iam9zkyzqebnf_okxipihkgjwnw.jpeg\" />\n",
    "    \n",
    "**<center>[mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course** </center><br>\n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). [mlcourse.ai](https://mlcourse.ai) is powered by [OpenDataScience (ods.ai)](https://ods.ai/) © 2017—2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6. Solution</center><a class=\"tocSkip\">\n",
    "### <center> Beating benchmarks in \"How good is your Medium article?\"</center><a class=\"tocSkip\">\n",
    "    \n",
    "[Competition](https://www.kaggle.com/c/how-good-is-your-medium-article). The task is to beat \"Assignment 6 baseline\". You can refer to [this simple Ridge baseline](https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline?rvi=1).\n",
    "    \n",
    "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel __#mlcourse_ai_eng__, pinned thread __#a6_bonus__. If you are sure that something is not 100% correct, please leave your feedback there*\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import Lasso, Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help to throw away all HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.fed = []\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return \"\".join(self.fed)\n",
    "\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:\n",
    "        result = json.loads(line)\n",
    "    except Exception as e:\n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(\" \")[-1].replace(\")\", \"\"))\n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = \" \"\n",
    "        new_line = \"\".join(new_line)\n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse JSON and extract some features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_write(path_to_data, inp_filename, is_train=True):\n",
    "\n",
    "    features = [\"content\", \"published\", \"title\", \"author\"]\n",
    "    prefix = \"train\" if is_train else \"test\"\n",
    "    feature_files = [\n",
    "        open(\n",
    "            os.path.join(path_to_data, \"{}_{}.txt\".format(prefix, feat)),\n",
    "            \"w\",\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "        for feat in features\n",
    "    ]\n",
    "\n",
    "    with open(\n",
    "        os.path.join(path_to_data, inp_filename), encoding=\"utf-8\"\n",
    "    ) as inp_json_file:\n",
    "\n",
    "        for line in tqdm(inp_json_file):\n",
    "            json_data = read_json_line(line)\n",
    "            for i, feat in enumerate(features):\n",
    "                if feat == \"published\":\n",
    "                    info = json_data[feat][\"$date\"]\n",
    "                elif feat == \"author\":\n",
    "                    info = json_data[feat][\"twitter\"]\n",
    "                    if info:\n",
    "                        info = info.replace(\"\\n\", \" \").replace(\"@\", \" \")\n",
    "                    else:\n",
    "                        info = \"\"\n",
    "                elif feat == \"content\" or feat == \"title\":\n",
    "                    info = json_data[feat].replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "                    info = strip_tags(info)\n",
    "                feature_files[i].write(info + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [competition data](https://www.kaggle.com/c/how-good-is-your-medium-article/data) and place it where it's convenient for you. You can modify the path to data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"../../_static/data/assignment6/\"  # modify this if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa75d9c3b8a448892ac09881d9f403f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3min 4s, sys: 2.15 s, total: 3min 6s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extract_features_and_write(PATH_TO_DATA, \"train.json\", is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fe8fa4c9a442a3b4e32b0dbdf4f78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 42s, sys: 1.26 s, total: 1min 44s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extract_features_and_write(PATH_TO_DATA, \"test.json\", is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tf-Idf with article content.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 2s, sys: 28 s, total: 7min 30s\n",
      "Wall time: 7min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(\n",
    "    os.path.join(PATH_TO_DATA, \"train_content.txt\"), encoding=\"utf-8\"\n",
    ") as input_train_file:\n",
    "    X_train_content_sparse = tfidf_vectorizer.fit_transform(input_train_file)\n",
    "\n",
    "with open(\n",
    "    os.path.join(PATH_TO_DATA, \"test_content.txt\"), encoding=\"utf-8\"\n",
    ") as input_test_file:\n",
    "    X_test_content_sparse = tfidf_vectorizer.transform(input_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 100000), (34645, 100000))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_content_sparse.shape, X_test_content_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tf-Idf with titles.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.92 s, sys: 83.1 ms, total: 5 s\n",
      "Wall time: 5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_vectorizer_title = TfidfVectorizer(ngram_range=(1, 3), max_features=100000)\n",
    "\n",
    "with open(\n",
    "    os.path.join(PATH_TO_DATA, \"train_title.txt\"), encoding=\"utf-8\"\n",
    ") as input_train_file:\n",
    "    X_train_title_sparse = tfidf_vectorizer_title.fit_transform(input_train_file)\n",
    "\n",
    "with open(\n",
    "    os.path.join(PATH_TO_DATA, \"test_title.txt\"), encoding=\"utf-8\"\n",
    ") as input_test_file:\n",
    "    X_test_title_sparse = tfidf_vectorizer_title.transform(input_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 100000), (34645, 100000))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_title_sparse.shape, X_test_title_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add time features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(path_to_publication_time_file):\n",
    "\n",
    "    df = pd.read_csv(path_to_publication_time_file, names=[\"time\"])\n",
    "    df[\"time\"] = df[\"time\"].apply(\n",
    "        lambda t: pd.to_datetime(t.replace(\"T\", \" \").replace(\"Z\", \"\"))\n",
    "    )\n",
    "    df[\"hour\"] = df[\"time\"].apply(lambda ts: ts.hour)\n",
    "    df[\"month\"] = df[\"time\"].apply(lambda ts: ts.month)\n",
    "\n",
    "    df[\"weekend\"] = (\n",
    "        df[\"time\"]\n",
    "        .apply(lambda ts: ts.weekday() == 5 or ts.weekday() == 6)\n",
    "        .astype(\"int\")\n",
    "    )\n",
    "\n",
    "    df[\"day\"] = ((df[\"hour\"] >= 12) & (df[\"hour\"] <= 18)).astype(\"int\")\n",
    "    df[\"morning\"] = ((df[\"hour\"] >= 7) & (df[\"hour\"] <= 11)).astype(\"int\")\n",
    "    df[\"night\"] = ((df[\"hour\"] >= 0) & (df[\"hour\"] <= 5)).astype(\"int\")\n",
    "\n",
    "    cols = [\"day\", \"morning\", \"night\", \"month\", \"weekend\"]\n",
    "    X_time_features_sparse = csr_matrix(df[cols].values)\n",
    "\n",
    "    return X_time_features_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 128 ms, total: 14.9 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_time_features_sparse = add_time_features(\n",
    "    os.path.join(PATH_TO_DATA, \"train_published.txt\")\n",
    ")\n",
    "X_test_time_features_sparse = add_time_features(\n",
    "    os.path.join(PATH_TO_DATA, \"test_published.txt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 5), (34645, 5))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_time_features_sparse.shape, X_test_time_features_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add authors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 s, sys: 2.3 s, total: 22.7 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "author_train = pd.read_csv(\n",
    "    os.path.join(PATH_TO_DATA, \"train_author.txt\"),\n",
    "    names=[\"author\"],\n",
    "    skip_blank_lines=False,\n",
    ")\n",
    "author_train = pd.get_dummies(author_train)\n",
    "\n",
    "author_test = pd.read_csv(\n",
    "    os.path.join(PATH_TO_DATA, \"test_author.txt\"),\n",
    "    names=[\"author\"],\n",
    "    skip_blank_lines=False,\n",
    ")\n",
    "author_test = pd.get_dummies(author_test)\n",
    "\n",
    "unique_authors_train = list(set(author_train.columns) - set(author_test.columns))\n",
    "unique_authors_test = list(set(author_test.columns) - set(author_train.columns))\n",
    "\n",
    "author_test = author_test.drop(unique_authors_test, axis=1)\n",
    "author_train = author_train.drop(unique_authors_train, axis=1)\n",
    "\n",
    "X_train_author_sparse = csr_matrix(author_train.values)\n",
    "X_test_author_sparse = csr_matrix(author_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 4587), (34645, 4587))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_author_sparse.shape, X_test_author_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join all sparse matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = hstack(\n",
    "    [\n",
    "        X_train_content_sparse,\n",
    "        X_train_title_sparse,\n",
    "        X_train_author_sparse,\n",
    "        X_train_time_features_sparse,\n",
    "    ]\n",
    ").tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse = hstack(\n",
    "    [\n",
    "        X_test_content_sparse,\n",
    "        X_test_title_sparse,\n",
    "        X_test_author_sparse,\n",
    "        X_test_time_features_sparse,\n",
    "    ]\n",
    ").tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 204592), (34645, 204592))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape, X_test_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read train target and split data for validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(\n",
    "    os.path.join(PATH_TO_DATA, \"train_log1p_recommends.csv\"), index_col=\"id\"\n",
    ")\n",
    "y_train = train_target[\"log_recommends\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid_sparse = X_train_sparse[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a simple Ridge model and check MAE on the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.103247357334841\n",
      "CPU times: user 2min 8s, sys: 18.4 s, total: 2min 26s\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge_reg = Ridge(random_state=17)\n",
    "ridge_reg.fit(X_train_part_sparse, y_train_part)\n",
    "ridge_valid_pred = ridge_reg.predict(X_valid_sparse)\n",
    "print(mean_absolute_error(y_valid, ridge_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot distributions of tagets and predictions for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_valid, bins=30, alpha=0.5, color=\"red\", label=\"true\", range=(0, 10))\n",
    "plt.hist(\n",
    "    ridge_valid_pred, bins=30, alpha=0.5, color=\"green\", label=\"pred\", range=(0, 10)\n",
    ")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 40s, sys: 21.6 s, total: 3min 1s\n",
      "Wall time: 38.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge_reg.fit(X_train_sparse, y_train)\n",
    "ridge_test_pred = ridge_reg.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(\n",
    "    prediction,\n",
    "    filename,\n",
    "    path_to_sample=os.path.join(PATH_TO_DATA, \"sample_submission.csv\"),\n",
    "):\n",
    "    submission = pd.read_csv(path_to_sample, index_col=\"id\")\n",
    "\n",
    "    submission[\"log_recommends\"] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(\n",
    "    ridge_test_pred, os.path.join(PATH_TO_DATA, \"assignment6_medium_submission.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With this you get ~ 1.73877 on public leaderboard.**\n",
    "\n",
    "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeroes. Make a submission. What do you get if you think about? How is it going to help you with modifying your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(\n",
    "    np.zeros_like(ridge_test_pred),\n",
    "    os.path.join(PATH_TO_DATA, \"medium_all_zeros_submission.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_target = 4.33328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate mean target for the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.051538598205832"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we now that we need to add the difference between test and train mean targets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_test_pred_modif = ridge_test_pred + mean_test_target - y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(\n",
    "    ridge_test_pred_modif,\n",
    "    os.path.join(PATH_TO_DATA, \"assignment6_medium_submission_with_hack.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the assignment. In case you'd like to try some more ideas for improvement:\n",
    "\n",
    "- Engineer good features, this is the key to success. Some simple features will be based on publication time, authors, content length and so on\n",
    "- You may not ignore HTML and extract some features from there\n",
    "- You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score\n",
    "- Try TF-IDF, ngrams, Word2Vec and GloVe embeddings\n",
    "- Try various NLP techniques like stemming and lemmatization\n",
    "- Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed\n",
    "- SGD and Vowpal Wabbit will train much faster\n",
    "- Play around with blending and/or stacking. An intro is given in [this Kernel](https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-simple-blending) by @yorko \n",
    "- And neural nets of course. We don't cover them in this course byt still transformer-based architectures will likely perform well in such types of tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
